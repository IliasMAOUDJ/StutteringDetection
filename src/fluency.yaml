seed: 84120
hpopt_mode: orion
hpopt: hpopt.yaml
ckpt_enable: True
batch_size: 16
noise_reduced: True
#--------------------------------- hparams ------------------------------------
train: fluencybank
test: fluencybank
tsne: True
balance: False
balance_ratio: 0.5
balance_test: False
number_of_epochs: 1
annot_value: 2
n_mels: 80
subset: all
siamese: False
dropout: 0.2
fold: 2
nr: False
#---------------------------------- Classes -----------------------------------
# 1+number of disfluencies to classify
remove_unsure: False
stutter: Interjection
Prolongation: False
Block: False
SoundRep: False
WordRep: False
Interjection: False
num_class: 1 #!!python/object/apply:eval [ !ref <Prolongation> + <Block> + <SoundRep> + <WordRep> + <Interjection>]
#----------------------------------- Feats ------------------------------------
input_freq: 16000
resample_freq: 16000
preaugment: False
normalize: False
augment: False

normalizer: !new:speechbrain.processing.features.InputNormalization

#----------------------------------- Loss -------------------------------------
weights: !new:torch.Tensor
    data: [5.31,8.18,7.67,1.88,4.88,8.87] #Repetition, Prolongation, Block, Interjection, Fluent
weight: 12
inverse_weight:  !!python/object/apply:eval [1 / 1 ]

positive: 1
weight_fl: 1
weight_dis: 1

label_smoothing: 0.0

multi_loss: !new:torch.nn.CrossEntropyLoss

#----------------------------------- Model ------------------------------------
models: wav2vec2
layers: 0 5 10 12
backbone: ResArch #vit_base_resnet50_384 #resnet18 #vit_small_patch16_224_dino #
with_pooling: True
source: facebook/wav2vec2-base-960h  #jonatasgrosman/wav2vec2-large-xlsr-53-japanese #facebook/wav2vec2-base-960h
#model: !new:model.models.MyWav2vec2
#    wav2vec2: !ref <wav2vec2>
#    source: !ref <source>
#    layers: !ref <layers>
#    mean: True
#    std: True
#    with_pooling: !ref <with_pooling>
#    dropout: !ref <dropout>
#    dropoutlstm: 0.5
#    hidden_size: 256
#    output_all_hiddens: True
#   num_class: !ref <num_class>
#    batch_size: !ref <batch_size>
#    num_layers: 2
#wav2vec2: !new:speechbrain.lobes.models.huggingface_transformers.wav2vec2.Wav2Vec2
#    source: !ref <source>
#    save_path: /hugging_face
#    output_all_hiddens: True
#    output_norm: True
#    freeze: True
#    freeze_feature_extractor: True
raw_input: True
model: !new:model.models.Ameer
#lstm: !new:speechbrain.nnet.RNN.LSTM
#    hidden_size: !ref <hidden_size>
#    input_size: 512
#    bidirectional: True
#    num_layers: 1
#    dropout: 0.4
  
#resbilstm: !new:model.models.ResNetBiLSTM
#    resnet: !ref <backbone>
#    bilstm: !ref <lstm>
#    num_classes: !ref <num_class>
#    freeze: False
#    fc_dim: !ref <fc_dim>
#    layers_to_freeze: 0
#    pretrain: True
#    
bin_classifier: !new:torch.nn.Linear
    in_features: 1024
    out_features: 1

multi_classifier: !new:torch.nn.Linear
    in_features: 1024
    out_features: !ref <num_class>
#-------------------------------- Scheduling ----------------------------------

dataloader_opts:
    batch_size: !ref <batch_size>
    shuffle: True

learning_rate: 0.00004
opt_class: !name:torch.optim.AdamW
    lr: !ref <learning_rate>
    weight_decay: 0.1

#---------------------------------- Misc --------------------------------------

__set_seed: !apply:torch.manual_seed [!ref <seed>]
output_folder: !ref results/<seed>

counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

modules:
    model: !ref <model>
    multi_loss: !ref <multi_loss>
    bin_classifier: !ref <bin_classifier>
    multi_classifier: !ref <multi_classifier>

save_folder: !ref <output_folder>/save
train_log: !ref <output_folder>/train_log.txt
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>
    recoverables:
        model: !ref <model>
        counter: !ref <counter>

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>


resnet: 512
ecapa: 192
wav2vec2_input: 768
vit: 768

